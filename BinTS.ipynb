{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from probts.data.data_utils.data_scaler import Scaler, StandardScaler, IdentityScaler, TemporalScaler, BinScaler, \\\n",
    "    BinaryQuantizer\n",
    "\n",
    "from probts.model.forecaster import LinearForecaster, NaiveForecaster\n",
    "from probts.model.forecast_module import ProbTSForecastModule\n",
    "from probts.data import ProbTSDataModule, DataManager, ProbTSBatchData\n",
    "from probts.utils import find_best_epoch\n",
    "from lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [],
   "source": [
    "# class BinaryQuantizer(Scaler):\n",
    "#     def __init__(self, num_bins=200, min_val=-10.0, max_val=10.0):\n",
    "#         super().__init__()\n",
    "#         self.num_bins = num_bins\n",
    "#         self.min_val = min_val\n",
    "#         self.max_val = max_val\n",
    "#         self.bin_values_ = torch.linspace(self.min_val, self.max_val, self.num_bins)\n",
    "#\n",
    "#     def fit(self, values):\n",
    "#         self.min_val = values.min()\n",
    "#         self.max_val = values.max()\n",
    "#         self.bin_values_ = torch.linspace(self.min_val, self.max_val, self.num_bins)\n",
    "#\n",
    "#     def fit_transform(self, values):\n",
    "#         self.fit(values)\n",
    "#         return self.transform(values)\n",
    "#\n",
    "#     def transform(self, values):\n",
    "#         bin_thresholds = self.bin_values_.reshape(1, 1, -1)\n",
    "#         return (values >= bin_thresholds).float()\n",
    "#\n",
    "#     def inverse_transform(self, values):\n",
    "#         reversed_bin = torch.flip(values, dims=(-1,))\n",
    "#         idx_first_one_reversed = reversed_bin.argmax(axis=-1)[..., None]\n",
    "#         idx_last_one = self.num_bins - 1 - idx_first_one_reversed\n",
    "#         reconstructed = self.bin_values_[idx_last_one]\n",
    "#         return reconstructed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [],
   "source": [
    "# class StandardBinScaler(Scaler):\n",
    "#     def __init__(self, standard: StandardScaler, bin: BinaryQuantizer):\n",
    "#         super().__init__()\n",
    "#         self.standard = standard\n",
    "#         self.bin = bin\n",
    "#\n",
    "#     def fit(self, X):\n",
    "#         Z = self.standard.fit_transform(X)\n",
    "#         self.bin.fit(Z)\n",
    "#         # print('the scaler was fitted')\n",
    "#\n",
    "#     def transform(self, X):\n",
    "#         Z = self.standard.transform(X)\n",
    "#         return self.bin.transform(Z)\n",
    "#\n",
    "#     def fit_transform(self, X):\n",
    "#         self.fit(X)\n",
    "#         return self.transform(X)\n",
    "#\n",
    "#     def inverse_transform(self, X):\n",
    "#         Z = self.bin.inverse_transform(X)\n",
    "#         return self.standard.inverse_transform(Z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [],
   "source": [
    "# data_manager = DataManager(\n",
    "#     dataset='tourism_monthly',\n",
    "#     path='../datasets',\n",
    "#     context_length=12,\n",
    "#     prediction_length=12,\n",
    "# )\n",
    "# data_manager.context_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [],
   "source": [
    "# class CustomDataManager(DataManager):\n",
    "#     def _configure_scaler(self, scaler_type: str):\n",
    "#         \"\"\"Configure the scaler.\"\"\"\n",
    "#         if scaler_type == \"standard\":\n",
    "#             return StandardScaler(var_specific=self.var_specific_norm)\n",
    "#         elif scaler_type == \"temporal\":\n",
    "#             return TemporalScaler()\n",
    "#         elif scaler_type == \"binary\":\n",
    "#             return BinaryQuantizer()\n",
    "#         elif scaler_type == \"normalization+binary\":\n",
    "#             # return StandardBinScaler(StandardScaler(var_specific=self.var_specific_norm), BinaryQuantizer())\n",
    "#             return BinScaler(TemporalScaler(), BinaryQuantizer())\n",
    "#         return IdentityScaler()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "outputs": [],
   "source": [
    "# data_module = ProbTSDataModule(\n",
    "#     data_manager=data_manager,\n",
    "#     batch_size=32,\n",
    "#     test_batch_size=32,\n",
    "#     num_workers=8,\n",
    "# )\n",
    "# test_dataloader = data_module.test_dataloader()\n",
    "# train_dataloader = data_module.train_dataloader()\n",
    "# val_dataloader = data_module.val_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "outputs": [],
   "source": [
    "# for test_batch in test_dataloader:\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "outputs": [],
   "source": [
    "# batch_data = ProbTSBatchData(test_batch, 'cpu')\n",
    "# batch_data.past_target_cdf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,3))\n",
    "# plt.plot(batch_data.past_target_cdf[13, :, 0].t())\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "outputs": [],
   "source": [
    "# scaler = StandardBinScaler(StandardScaler(), BinaryQuantizer())\n",
    "# scaler.fit(batch_data.past_target_cdf)\n",
    "# transformed = scaler.transform(batch_data.past_target_cdf)\n",
    "# transformed.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,3))\n",
    "# plt.imshow(transformed[13].T, aspect='auto', interpolation='none', cmap='Reds')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "outputs": [],
   "source": [
    "# reconstructed = scaler.inverse_transform(transformed)\n",
    "# reconstructed.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,3))\n",
    "# plt.plot(reconstructed[13, :, 0].t())\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Short-term Dataset: m4_weekly\n",
      "No validation set is used.\n"
     ]
    }
   ],
   "source": [
    "data_manager = DataManager(\n",
    "    # dataset='tourism_monthly',\n",
    "    # dataset='m4_daily',\n",
    "    dataset='m4_weekly',\n",
    "    path='../datasets',\n",
    "    context_length=39,\n",
    "    prediction_length=13,\n",
    "    scaler=\"identity\",\n",
    ")\n",
    "\n",
    "# data_manager = DataManager(\n",
    "#     dataset='m4_daily',\n",
    "#     # dataset='etth1',\n",
    "#     path='./datasets',\n",
    "#     context_length=12,\n",
    "#     prediction_length=12,\n",
    "#     scaler=\"standard_binary\",\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "outputs": [],
   "source": [
    "# data_manager.dataset_raw.training_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "outputs": [
    {
     "data": {
      "text/plain": "39"
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.context_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "outputs": [],
   "source": [
    "data_module = ProbTSDataModule(\n",
    "    data_manager=data_manager,\n",
    "    batch_size=1,\n",
    "    test_batch_size=1,\n",
    "    num_workers=8,\n",
    ")\n",
    "test_dataloader = data_module.test_dataloader()\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "val_dataloader = data_module.val_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "outputs": [],
   "source": [
    "for test_batch in test_dataloader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 40])"
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['past_target_cdf'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([40, 1])"
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['past_target_cdf'].reshape(-1, 1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [],
   "source": [
    "# data_manager.scaler.standard.mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[36379.6602],\n        [38543.0391],\n        [38543.0391],\n        [37987.6094],\n        [37987.6094],\n        [38806.2891],\n        [38806.2891],\n        [38814.1094],\n        [38814.1094],\n        [39440.6094],\n        [39440.6094],\n        [38559.3398],\n        [38559.3398],\n        [38886.2109],\n        [38886.2109],\n        [38672.6289],\n        [38672.6289],\n        [38314.7812],\n        [38314.7812],\n        [38262.3281],\n        [38262.3281],\n        [38698.1289],\n        [38698.1289],\n        [38619.6992],\n        [38619.6992],\n        [37171.8086],\n        [37171.8086],\n        [37828.6484],\n        [37828.6484],\n        [37894.9102],\n        [37894.9102],\n        [38264.0391],\n        [38264.0391],\n        [38126.4805],\n        [38126.4805],\n        [38429.9297],\n        [38429.9297],\n        [36565.1797],\n        [36565.1797],\n        [35397.1602]])"
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.scaler.transform(test_batch['past_target_cdf'].reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [],
   "source": [
    "# for train_batch in train_dataloader:\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "outputs": [],
   "source": [
    "# batch_data = ProbTSBatchData(test_batch, 'cpu')\n",
    "# batch_data.past_target_cdf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "outputs": [
    {
     "data": {
      "text/plain": "39"
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.context_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "outputs": [],
   "source": [
    "from probts.model.forecaster.prob_forecaster.binconv import BinConv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "outputs": [],
   "source": [
    "### h = 2, L =5\n",
    "### total: 7\n",
    "### target indexes: 5,6\n",
    "## h=0 - 0:5 [0,1,2,3,4]\n",
    "## h=1 - 1:6 [1,2,3,4,5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "outputs": [],
   "source": [
    "# def most_probable_monotonic_sequence(p: torch.Tensor, is_sample: bool, eps: float = 1e-6):\n",
    "#     \"\"\"\n",
    "#     p: Tensor of shape (B, D) with probabilities\n",
    "#     Returns:\n",
    "#         best_sequences: Tensor of shape (B, D) with the most probable [1...1, 0...0] sequence\n",
    "#         best_probs: Tensor of shape (B,) with normalized probability of the best sequence\n",
    "#     \"\"\"\n",
    "#     B, D = p.shape\n",
    "#\n",
    "#     # Clamp p to avoid log(0) or log(1) instability\n",
    "#     p_clamped = p.clamp(min=eps, max=1 - eps)\n",
    "#\n",
    "#     # Use log domain to compute cumulative products\n",
    "#     log_p = torch.log(p_clamped)\n",
    "#     log_1_minus_p = torch.log(1 - p_clamped)\n",
    "#\n",
    "#     log_success = torch.cumsum(log_p, dim=1)  # shape (B, D)\n",
    "#     log_fail = torch.cumsum(log_1_minus_p.flip(dims=[1]), dim=1).flip(dims=[1])  # shape (B, D)\n",
    "#\n",
    "#     # Pad with log(1) = 0 to align indexing\n",
    "#     zero = torch.zeros((B, 1), dtype=p.dtype, device=p.device)\n",
    "#     log_success = torch.cat([zero, log_success], dim=1)  # shape (B, D+1)\n",
    "#     log_fail = torch.cat([log_fail, zero], dim=1)        # shape (B, D+1)\n",
    "#\n",
    "#     # Sum log-probs for each possible cutoff (index k: first 0 after all 1s)\n",
    "#     log_probs = log_success + log_fail  # shape (B, D+1)\n",
    "#     log_probs_max = torch.max(log_probs, dim=1, keepdim=True)[0]\n",
    "#     probs_normalized = torch.exp(log_probs - log_probs_max)\n",
    "#     probs_normalized = probs_normalized / probs_normalized.sum(dim=1, keepdim=True)\n",
    "#\n",
    "#     # Sample or take the most probable index\n",
    "#     if is_sample:\n",
    "#         k = torch.multinomial(probs_normalized, num_samples=1)\n",
    "#     else:\n",
    "#         k = torch.argmax(probs_normalized, dim=1, keepdim=True)\n",
    "#\n",
    "#     # Create the monotonic sequence [1,...,1,0,...,0]\n",
    "#     arange = torch.arange(D, device=p.device).unsqueeze(0)\n",
    "#     best_sequences = (arange < k).to(p.dtype)  # shape (B, D)\n",
    "#\n",
    "#     best_probs = torch.gather(probs_normalized, dim=1, index=k).squeeze(1)\n",
    "#\n",
    "#     return best_sequences, best_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "outputs": [],
   "source": [
    "# most_probable_monotonic_sequence(torch.tensor([1.0, 0.2]).reshape(1, -1), False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "outputs": [],
   "source": [
    "# class DynamicTanh(nn.Module):\n",
    "#     def __init__(self, normalized_shape, channels_last, alpha_init_value=0.5):\n",
    "#         super().__init__()\n",
    "#         self.normalized_shape = normalized_shape\n",
    "#         self.alpha_init_value = alpha_init_value\n",
    "#         self.channels_last = channels_last\n",
    "#\n",
    "#         self.alpha = nn.Parameter(torch.ones(1) * alpha_init_value)\n",
    "#         self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "#         self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = torch.tanh(self.alpha * x)\n",
    "#         if self.channels_last:\n",
    "#             x = x * self.weight + self.bias\n",
    "#         else:\n",
    "#             # x = x * self.weight[:, None, None] + self.bias[:, None, None]\n",
    "#             x = x * self.weight[:, None] + self.bias[:, None]\n",
    "#         return x\n",
    "#\n",
    "#     def extra_repr(self):\n",
    "#         return f\"normalized_shape={self.normalized_shape}, alpha_init_value={self.alpha_init_value}, channels_last={self.channels_last}\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [],
   "source": [
    "# from probts.model.forecaster import Forecaster\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "#\n",
    "#\n",
    "# class BinConv(Forecaster):\n",
    "#     def __init__(self, context_length: int, is_prob_forecast: bool, num_bins: int, kernel_size_across_bins_2d: int = 3,\n",
    "#                  kernel_size_across_bins_1d: int = 3, num_filters_2d: int = 8,\n",
    "#                  num_filters_1d: int = 32, is_cum_sum: bool = False, num_1d_layers: int = 2, num_blocks: int = 3,\n",
    "#                  kernel_size_ffn: int = 51, dropout: float = 0.2,\n",
    "#                  **kwargs) -> None:\n",
    "#         \"\"\"\n",
    "#         Initialize the model with parameters.\n",
    "#         \"\"\"\n",
    "#         super().__init__(context_length=context_length, **kwargs)\n",
    "#         # Initialize model parameters here\n",
    "#         self.context_length = context_length\n",
    "#         self.num_bins = num_bins\n",
    "#         self.is_prob_forecast = is_prob_forecast\n",
    "#         self.num_filters_2d = num_filters_2d\n",
    "#         self.num_filters_1d = num_filters_1d\n",
    "#         self.kernel_size_across_bins_2d = kernel_size_across_bins_2d\n",
    "#         self.kernel_size_across_bins_1d = kernel_size_across_bins_1d\n",
    "#         self.is_cum_sum = is_cum_sum\n",
    "#         self.scaler = BinScaler(StandardScaler(var_specific=True), BinaryQuantizer())\n",
    "#         self.num_1d_layers = num_1d_layers\n",
    "#         self.num_blocks = num_blocks\n",
    "#         self.kernel_size_ffn = kernel_size_ffn\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         # Conv2d over (context_length, num_bins)\n",
    "#\n",
    "#         self.conv2d = nn.ModuleList([nn.Conv2d(\n",
    "#             in_channels=1,\n",
    "#             out_channels=self.num_filters_2d,\n",
    "#             # kernel_size=(context_length if i == 0 else kernel_size_across_bins_2d, kernel_size_across_bins_2d),\n",
    "#             kernel_size=(context_length, kernel_size_across_bins_2d),\n",
    "#             bias=True\n",
    "#         ) for _ in range(num_blocks)\n",
    "#         ])\n",
    "#         self.conv1d = nn.ModuleList([\n",
    "#             nn.ModuleList([\n",
    "#                 nn.Conv1d(in_channels=num_filters_2d if i == 0 else num_filters_1d,\n",
    "#                           out_channels=context_length if i == num_1d_layers - 1 else num_filters_1d,\n",
    "#                           kernel_size=kernel_size_across_bins_1d, bias=True,\n",
    "#                           groups=num_filters_1d)\n",
    "#                 # groups=1)\n",
    "#                 for i in range(num_1d_layers)\n",
    "#             ]) for _ in range(num_blocks)\n",
    "#         ])\n",
    "#         self.conv_ffn = nn.Conv1d(\n",
    "#             # in_channels=self.num_filters_1d,\n",
    "#             in_channels=context_length,\n",
    "#             out_channels=1,\n",
    "#             kernel_size=kernel_size_ffn,  # large kernel size?\n",
    "#             groups=1,\n",
    "#             bias=True\n",
    "#         )\n",
    "#         print('conv 2d:')\n",
    "#         print(self.conv2d)\n",
    "#         print('conv 1d:')\n",
    "#         print(self.conv1d)\n",
    "#         print('conv ffn:')\n",
    "#         print(self.conv_ffn)\n",
    "#         assert num_filters_2d == num_filters_1d, \"todo: change the self.act shape if not\"\n",
    "#         self.act = nn.ModuleList([\n",
    "#             nn.ModuleList([\n",
    "#                 # DynamicTanh(normalized_shape=num_filters_2d if i == 0 else num_filters_1d, channels_last=False)\n",
    "#                 DynamicTanh(normalized_shape=num_filters_2d if i < self.num_1d_layers else context_length,\n",
    "#                             channels_last=False)\n",
    "#                 for i in range(self.num_1d_layers + 1)  # applied after conv2d, and all conv1d including the last one\n",
    "#             ]) for _ in range(self.num_blocks)\n",
    "#         ])\n",
    "#\n",
    "#     def _pad_channels(self, tensor: torch.Tensor, pad_size: int, pad_val_left=1.0, pad_val_right=0.0):\n",
    "#         if pad_size == 0:\n",
    "#             return tensor\n",
    "#         left = torch.full((*tensor.shape[:-1], pad_size), pad_val_left, device=tensor.device)\n",
    "#         right = torch.full((*tensor.shape[:-1], pad_size), pad_val_right, device=tensor.device)\n",
    "#         return torch.cat([left, tensor, right], dim=-1)\n",
    "#\n",
    "#     def conv_layer(self, x: torch.Tensor, conv_func, act_func, kernel_size: int, is_2d: bool, ):\n",
    "#         # kernel_size = self.kernel_size_across_bins_2d if is_2d else self.kernel_size_across_bins_1d\n",
    "#         pad = kernel_size // 2 if kernel_size > 1 else 0\n",
    "#         x_padded = self._pad_channels(x, pad)\n",
    "#         if is_2d:\n",
    "#             x_padded = x_padded.unsqueeze(1)\n",
    "#         conv_out = conv_func(x_padded)  # (batch_size, num_filters_2d, num_bins)\n",
    "#\n",
    "#         if is_2d:\n",
    "#             conv_out = conv_out.squeeze(2)\n",
    "#         if act_func is not None:\n",
    "#             conv_out = act_func(conv_out)\n",
    "#         return conv_out\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#\n",
    "#         x = x.float()\n",
    "#         # x: (batch_size, context_length, num_bins)\n",
    "#         batch_size, context_length, num_bins = x.shape\n",
    "#         assert context_length == self.context_length, \"Mismatch in context length\"\n",
    "#\n",
    "#         for j in range(self.num_blocks):\n",
    "#\n",
    "#             residual = x\n",
    "#             x = self.conv_layer(x, self.conv2d[j], self.act[j][0], self.kernel_size_across_bins_2d, True)\n",
    "#             for i in range(self.num_1d_layers):\n",
    "#                 # x = self.conv_layer(x, self.conv1d[j][i], self.act[j][i + 1], False)\n",
    "#                 x = self.conv_layer(x, self.conv1d[j][i], F.relu,\n",
    "#                                     self.kernel_size_across_bins_1d, False)\n",
    "#             x = self.dropout(x)\n",
    "#             x = x + residual\n",
    "#\n",
    "#         out = self.conv_layer(x, self.conv_ffn, None, self.kernel_size_ffn, False).squeeze(1)\n",
    "#         # out = self.conv_ffn(x.squeeze(1))\n",
    "#\n",
    "#         if self.is_cum_sum:\n",
    "#             assert False, \"It degrades the performance\"\n",
    "#             out = torch.flip(torch.cumsum(torch.flip(out, dims=[1]), dim=1), dims=[1])\n",
    "#         return out\n",
    "#\n",
    "#     def loss(self, batch_data):\n",
    "#         \"\"\"\n",
    "#         Compute the loss for the given batch data.\n",
    "#\n",
    "#         Parameters:\n",
    "#         batch_data [dict]: Dictionary containing input data and possibly target data.\n",
    "#\n",
    "#         Returns:\n",
    "#         Tensor: Computed loss.\n",
    "#         \"\"\"\n",
    "#         # Extract inputs and targets from batch_data\n",
    "#         inputs = self.get_inputs(batch_data, 'all')\n",
    "#         orig_target = inputs[:, -self.prediction_length:, :]\n",
    "#\n",
    "#         self.scaler.fit(inputs.reshape(-1)[:-self.prediction_length])\n",
    "#         inputs = self.scaler.transform(inputs)\n",
    "#\n",
    "#         target = inputs[:, -self.prediction_length:, :]\n",
    "#         inputs = sliding_window_batch(inputs, self.context_length, self.prediction_length).float()\n",
    "#         outputs = self(inputs.view(-1, *inputs.shape[2:]))\n",
    "#         loss = F.binary_cross_entropy_with_logits(input=outputs, target=target.view(-1, *target.shape[2:]), )\n",
    "#         # print(f'loss: {loss}')\n",
    "#         return loss\n",
    "#\n",
    "#     def forecast(self, batch_data, num_samples=None):\n",
    "#         do_sample = num_samples is not None and num_samples > 1 and self.is_prob_forecast\n",
    "#\n",
    "#         inputs = self.get_inputs(batch_data, 'encode')\n",
    "#\n",
    "#         self.scaler.fit(inputs.reshape(-1))\n",
    "#         inputs = self.scaler.transform(inputs)\n",
    "#         if do_sample:\n",
    "#             inputs = repeat(inputs.unsqueeze(1), num_samples, 1)  # (B, NS, T, D)\n",
    "#             batch_size = inputs.shape[0]\n",
    "#             inputs = inputs.view(-1, *inputs.shape[2:])\n",
    "#         current_context = inputs.clone()\n",
    "#         forecasts = []\n",
    "#         for _ in range(self.prediction_length):\n",
    "#             pred = F.sigmoid(self(current_context))  # (B, D)\n",
    "#             # pred = (pred >= 0.5).int()\n",
    "#             pred, _ = most_probable_monotonic_sequence(pred, do_sample)\n",
    "#             pred = pred.int()\n",
    "#             forecasts.append(pred.unsqueeze(1))  # (B, 1, D)\n",
    "#             next_input = pred.unsqueeze(1)\n",
    "#             current_context = torch.cat([current_context[:, 1:], next_input], dim=1)\n",
    "#\n",
    "#         forecasts = torch.cat(forecasts, dim=1)\n",
    "#         forecasts = self.scaler.inverse_transform(forecasts)\n",
    "#         if do_sample:\n",
    "#             forecasts = forecasts.view(batch_size, num_samples, *forecasts.shape[1:])\n",
    "#         else:\n",
    "#             forecasts = forecasts.unsqueeze(1)  # (B, 1,  T, D)\n",
    "#         return forecasts\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [
    {
     "data": {
      "text/plain": "39"
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.context_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv 2d layers:\n",
      "ModuleList(\n",
      "  (0-2): 3 x Conv2d(1, 39, kernel_size=(39, 3), stride=(1, 1))\n",
      ")\n",
      "conv 1d layers:\n",
      "ModuleList(\n",
      "  (0-2): 3 x ModuleList(\n",
      "    (0-1): 2 x Conv1d(39, 39, kernel_size=(7,), stride=(1,), groups=39)\n",
      "  )\n",
      ")\n",
      "conv ffn layer:\n",
      "Conv1d(39, 1, kernel_size=(51,), stride=(1,))\n",
      "sampling_weight_scheme: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'forecaster' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['forecaster'])`.\n"
     ]
    }
   ],
   "source": [
    "forecaster = BinConv(\n",
    "    num_bins=200,\n",
    "    is_prob_forecast=False,\n",
    "    scaler_type='temporal',\n",
    "    kernel_size_across_bins_2d=3,\n",
    "    kernel_size_across_bins_1d=7,\n",
    "    num_filters_2d=39,\n",
    "    num_filters_1d=39,\n",
    "    kernel_size_ffn=51,\n",
    "    num_1d_layers=2,\n",
    "    num_blocks=3,\n",
    "    dropout=0.25,\n",
    "    use_lags=False,\n",
    "    use_feat_idx_emb=False,\n",
    "    use_time_feat=False,\n",
    "    target_dim=data_manager.target_dim,\n",
    "    context_length=data_manager.context_length,\n",
    "    prediction_length=data_manager.prediction_length,\n",
    "    freq=data_manager.freq,\n",
    "    lags_list=data_manager.lags_list,\n",
    "    time_feat_dim=data_manager.time_feat_dim,\n",
    "    dataset=data_manager.dataset,\n",
    ")\n",
    "model = ProbTSForecastModule(\n",
    "    forecaster=forecaster,\n",
    "    scaler=data_manager.scaler,\n",
    "    learning_rate=0.001,\n",
    "    quantiles_num=20,\n",
    "    num_samples=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    strategy=\"auto\",\n",
    "    max_epochs=50,\n",
    "    use_distributed_sampler=False,\n",
    "    limit_train_batches=100,\n",
    "    log_every_n_steps=1,\n",
    "    accumulate_grad_batches=8,\n",
    "    default_root_dir='./results',\n",
    "    logger=CSVLogger('./logs'),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [],
   "source": [
    "target = []\n",
    "for data in list(data_manager.dataset_raw.train):\n",
    "    target.append(data['target'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# model.scaler.fit(torch.tensor(np.concatenate(target)).reshape(-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "outputs": [],
   "source": [
    "# model.scaler.standard.mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type    | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | forecaster | BinConv | 18.4 K | train\n",
      "-----------------------------------------------\n",
      "18.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.4 K    Total params\n",
      "0.074     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cca43a66946c4ffabc1fc51da35a4b7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:106: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3a40166be1643668b62a972bc3391f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [
    {
     "data": {
      "text/plain": "       train_loss\nepoch            \n0        0.884135\n1        0.531067\n2        0.397401\n3        0.302372\n4        0.269730\n5        0.393228\n6        0.236240\n7        0.285866\n8        0.241013\n9        0.172442\n10       0.252686\n11       0.169197\n12       0.248379\n13       0.156746\n14       0.214481\n15       0.194621\n16       0.173213\n17       0.151696\n18       0.173621\n19       0.263954\n20       0.288207\n21       0.210755\n22       0.208182\n23       0.138725\n24       0.197428\n25       0.215114\n26       0.293543\n27       0.137308\n28       0.206784\n29       0.189774\n30       0.234562\n31       0.210685\n32       0.163738\n33       0.177260\n34       0.158964\n35       0.208693\n36       0.206570\n37       0.227951\n38       0.198683\n39       0.208733\n40       0.231595\n41       0.218016\n42       0.184842\n43       0.224541\n44       0.197199\n45       0.178261\n46       0.280518\n47       0.181258\n48       0.179394\n49       0.213314\n50            NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_loss</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.884135</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.531067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.397401</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.302372</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.269730</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.393228</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.236240</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.285866</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.241013</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.172442</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.252686</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.169197</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.248379</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.156746</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.214481</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.194621</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.173213</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.151696</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.173621</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.263954</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.288207</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.210755</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.208182</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.138725</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.197428</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.215114</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.293543</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.137308</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.206784</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.189774</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.234562</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.210685</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.163738</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.177260</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.158964</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.208693</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.206570</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.227951</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.198683</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.208733</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.231595</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.218016</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.184842</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.224541</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.197199</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.178261</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.280518</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.181258</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.179394</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.213314</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('logs/lightning_logs/version_254/metrics.csv')\n",
    "df.groupby('epoch').agg({'train_loss': 'mean'})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "### TODO: what does individual mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [],
   "source": [
    "i = 2\n",
    "for test_batch in test_dataloader:\n",
    "    if i > 0:\n",
    "        break\n",
    "    print(i)\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 40])"
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch['past_target_cdf'].shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "outputs": [],
   "source": [
    "batch_data = ProbTSBatchData(test_batch, model.device)\n",
    "past_target_cdf = model.scaler.transform(batch_data.past_target_cdf)\n",
    "future_target_cdf = model.scaler.transform(batch_data.future_target_cdf)\n",
    "batch_data.past_target_cdf = past_target_cdf\n",
    "\n",
    "batch_idx = 0\n",
    "with torch.no_grad():\n",
    "    prediction = model.forecaster.forecast(batch_data, num_samples=5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 13, 1])"
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[35661.3047],\n          [35640.9883],\n          [35661.3047],\n          [35559.7109],\n          [35559.7109],\n          [35519.0742],\n          [35620.6680],\n          [35519.0742],\n          [35417.4805],\n          [35458.1172],\n          [35458.1172],\n          [35437.7969],\n          [39440.6094]]]])"
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction  #.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "outputs": [
    {
     "data": {
      "text/plain": "<probts.data.data_wrapper.ProbTSBatchData at 0x2d2b32a40>"
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([36379.6602])"
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.past_target_cdf[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[35661.3047],\n          [35640.9883],\n          [35661.3047],\n          [35559.7109],\n          [35559.7109],\n          [35519.0742],\n          [35620.6680],\n          [35519.0742],\n          [35417.4805],\n          [35458.1172],\n          [35458.1172],\n          [35437.7969],\n          [39440.6094]]]])"
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scaler.inverse_transform(prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[35661.3047],\n          [35640.9883],\n          [35661.3047],\n          [35559.7109],\n          [35559.7109],\n          [35519.0742],\n          [35620.6680],\n          [35519.0742],\n          [35417.4805],\n          [35458.1172],\n          [35458.1172],\n          [35437.7969],\n          [39440.6094]]]])"
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scaler.inverse_transform(prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[35397.1602],\n         [35808.5898],\n         [35808.5898],\n         [36246.1406],\n         [36246.1406],\n         [36403.6992],\n         [36403.6992],\n         [36150.1992],\n         [36150.1992],\n         [35790.5508],\n         [35790.5508],\n         [34066.9492],\n         [34066.9492]]])"
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scaler.inverse_transform(future_target_cdf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([35397.1602, 35808.5898, 35808.5898, 36246.1406, 36246.1406, 36403.6992,\n        36403.6992, 36150.1992, 36150.1992, 35790.5508, 35790.5508, 34066.9492,\n        34066.9492])"
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.future_target_cdf.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2cc56f370>]"
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.scaler.inverse_transform(prediction).reshape(-1), c='r')\n",
    "plt.plot(batch_data.future_target_cdf.reshape(-1), c='b')\n",
    "plt.plot(model.scaler.inverse_transform(future_target_cdf).reshape(-1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 40, 1])"
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.past_target_cdf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "outputs": [],
   "source": [
    "# context_length = data_manager.context_length\n",
    "# prediction_length = data_manager.prediction_length\n",
    "# past_range = range(0, context_length)\n",
    "# future_range = range(context_length, context_length + prediction_length)\n",
    "# full_range = range(0, context_length + prediction_length)\n",
    "#\n",
    "# for i in range(min(10, forecaster.target_dim)):\n",
    "#     target = torch.cat([past_target_cdf[batch_idx, -context_length:, i], future_target_cdf[batch_idx, :, i]])\n",
    "#     plt.figure(figsize=(10, 2))\n",
    "#     plt.plot(full_range, target)\n",
    "#     plt.plot(future_range, prediction[:, i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7cbb53040c044bbc9b8c08347c046ee1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/numpy/lib/function_base.py:4824: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "      13_test_CRPS          0.14245367050170898\n",
      "    13_test_CRPS-Sum        0.14245367050170898\n",
      "      13_test_MASE           3.769092082977295\n",
      "       13_test_MSE              857140.6875\n",
      "     13_test_MSE-Sum            857140.6875\n",
      "       13_test_ND           0.14245367050170898\n",
      "     13_test_ND-Sum         0.14245367050170898\n",
      "      13_test_NRMSE         0.16772165894508362\n",
      "    13_test_NRMSE-Sum       0.16772165894508362\n",
      "   13_test_weighted_ND      0.14245367050170898\n",
      " 13_test_weighted_ND-Sum    0.14245367050170898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "trainer.test(model=model, datamodule=data_module);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 13, 1])"
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_target_cdf.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 10, 2])"
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from probts.utils import repeat\n",
    "\n",
    "repeat(torch.rand(5, 2).unsqueeze(1), 10, 1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
